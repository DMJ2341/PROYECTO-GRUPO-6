# backend/scripts/load_nist_glossary.py

import json
import os
import sys
from sqlalchemy.exc import IntegrityError

# AÃ±adir el path para importar mÃ³dulos locales
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from database.db import get_session, create_all
from models.glossary import Glossary

# --- CONFIGURACIÃ“N ---
MAX_TERMS = 500 

def load_terms_from_json(session, terms_data):
    """Procesa una lista de tÃ©rminos desde JSON y los carga a la BD."""
    count = 0
    error_occurred = False
    
    # Extraer la lista si el JSON tiene una clave raÃ­z "terms" (comÃºn en APIs), 
    # o usar la lista directa si el JSON es una lista [].
    if isinstance(terms_data, dict) and "terms" in terms_data:
        items = terms_data["terms"]
    else:
        items = terms_data

    print(f"ğŸ“‚ Procesando {len(items)} elementos...")

    for term_data in items:
        try:
            # 1. Obtener datos bilingÃ¼es del JSON
            # Nota: Usamos .get() con valores por defecto para evitar errores si falta algo
            t_en = term_data.get('term_en', '').strip()
            t_es = term_data.get('term_es', '').strip()
            d_en = term_data.get('definition_en', '').strip()
            d_es = term_data.get('definition_es', '').strip()
            
            # ValidaciÃ³n: Deben existir al menos los tÃ©rminos y definiciones bÃ¡sicos
            if not t_en or not t_es or not d_en or not d_es:
                print(f"âš ï¸ Saltando tÃ©rmino incompleto: {t_en or t_es}")
                continue
            
            # 2. Verificar duplicados (buscamos por el tÃ©rmino en inglÃ©s como clave principal)
            existing = session.query(Glossary).filter_by(term_en=t_en).first()
            if existing:
                # Opcional: Actualizar si ya existe
                continue

            # 3. Crear el nuevo objeto Glossary con estructura BILINGÃœE
            new_term = Glossary(
                term_en=t_en,
                term_es=t_es,
                definition_en=d_en,
                definition_es=d_es,
                # Metadata opcional
                acronym=term_data.get('acronym'),
                category=term_data.get('category', 'General'),
                difficulty=term_data.get('difficulty', 'beginner'),
                example_en=term_data.get('example_en'),
                example_es=term_data.get('example_es'),
                where_you_hear_it=term_data.get('source') # O el campo que corresponda en tu JSON
            )

            session.add(new_term)
            count += 1
            if count >= MAX_TERMS:
                break
        
        except IntegrityError as e:
            print(f"âŒ Error de integridad: {e}")
            session.rollback()
            error_occurred = True
        except Exception as e:
            print(f"âŒ Error general en {term_data.get('term_en', 'Desconocido')}: {e}")
            session.rollback()
            error_occurred = True

    if not error_occurred and count > 0:
        session.commit()
        print("ğŸ’¾ Commit realizado con Ã©xito.")
    
    return count

def run_glossary_loader():
    print("--- ğŸš€ INICIANDO CARGA DE GLOSARIO BILINGÃœE ---")
    session = get_session()
    
    try:
        # AsegÃºrate de que este archivo tambiÃ©n tenga la estructura nueva (term_en, term_es, etc.)
        data_path = os.path.join(os.path.dirname(__file__), '..', 'data', 'glossary_data.json')
        
        with open(data_path, 'r', encoding='utf-8') as f:
            glossary_json = json.load(f)
            print("âœ… Archivo JSON leÃ­do correctamente.")
            
    except FileNotFoundError:
        print(f"âŒ Error: No se encuentra el archivo en {data_path}")
        return
    except json.JSONDecodeError:
        print("âŒ Error: JSON mal formado.")
        return

    try:
        total = load_terms_from_json(session, glossary_json)
        print(f"ğŸ‰ Finalizado: {total} tÃ©rminos cargados.")
    except Exception as e:
        print(f"âŒ Error crÃ­tico: {e}")
    finally:
        session.close()

if __name__ == '__main__':
    create_all() # Asegura que la tabla exista antes de insertar
    run_glossary_loader()